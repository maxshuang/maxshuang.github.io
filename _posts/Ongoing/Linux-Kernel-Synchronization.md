---
layout: post
title: Linux Kernel-Synchronization(Basic)
subtitle: picture from https://www.pexels.com/search/wild%20animals/
author: maxshuang
categories: Linux-Kernel
banner:
  image: /assets/images/post/linux-kernel-synchronization/pexels-david-selbert-15578852.jpg
  opacity: 0.618
  background: "#000"
  height: "55vh"
  min_height: "38vh"
  heading_style: "font-size: 3.00em; font-weight: bold; text-decoration: underline"
  subheading_style: "color: gold"
tags: Linux-Kernel Lock
---

## 锁是什么
今天讲一个非常有意思，并且非常常见的话题---**锁**。

我最早接触"锁"的概念是在接触多线程编程的时候，锁是保护同一份数据被多个执行线程/进程同时访问时，保证数据完整的必备工具。

如果不考虑的锁的实现，只考虑锁的原语，我们可以这样想象，为了有序得获取房间中的物资，多个人需要依次顺序对门加锁，拿东西，然后解锁门以便让下一个人进入。这样不管多个人是排成一条队还是散乱得挤在门口，任何时刻都只能有一个人能进入门内。

随着编程得深入，我逐渐接触到各种各种的锁，比如 linux kernel 中的临界区，读写锁和自旋锁，数据库中的 row lock, gap lock, next-key lock 和 intension lock，java 中 ReentrantLock，StampedLock 和 Latch，甚至高并发数据结构中的无锁数据结构。

我逐渐迷失在各种各样的锁中，并且逐渐疑惑了起来，

**锁到底是什么？**

已经存在的这些锁底层是什么？为什么说锁会带来开销？如何创造新的锁？

## 对互斥的共识
并发中的锁首先是一种*共识*，它是在特定 context 下对互斥访问的*共识*。

说得具体一点，在一个生活场景中，10 个人要喝一杯水，但要求只能有一个人能喝到，这个时候我约定先口算出 $19*19$ 的人就可以喝到。在这样的 context 中，我约定了每个人口算出 $19*19$ 的时间是不同的。所以计算行为 "口算出 $19*19$" 在这个场景下就是一种锁，因为它可以在 context 下对互斥访问达成*共识*。

回到我们编程语言中的锁，因为编程语言本身要转换成机器语言，所以编程语言中的锁是基于 kernel context 提供的对互斥访问的*共识*。要了解锁是什么，就要了解 kernel context 提供了哪些对互斥访问的*共识*。

### 无锁场景
最简单的场景就是不需要锁，不需要对互斥访问的*共识*。在多核环境下，如果并发流是 CPU，则我们设置每 CPU 变量；如果并发流是多线程，我们设置每线程变量，如果并发流是多进程，那我们设置多进程变量。这样我们就需要考虑锁的概念了。

内核中就设置了每 CPU 变量，意思简单明了，该变量不会被多个 CPU 同时执行，比较有名的例子就是每 CPU 的 runqueue。

还有就是用户态下定义的线程本地变量：
```
_thread int a;
```
表达的也是一个意思，不同线程拥有不同的副本，虽然在定义上是相同的变量名，但是在不同线程内存中它们执行的不是同一份 int 类型内存。

而用户在调用 fork 之后，copy on write 机制会保证数据页在任意一方修改时会触发 deep copy, 此时父子进程操作的是不同的资源，自然不需要对互斥访问的*共识*。 

为了再深入去解释 kernel context 对互斥访问的*共识*概念，我们看个有点反直觉的场景。
#### 内核抢占
理论和定义上看每 CPU 变量是可以保证数据安全的，毕竟其他 CPU 上不管执行哪个逻辑流，都不会访问本 CPU 变量的值。

tricky 的地方在于本地 CPU 不是顺序执行的，在开内核抢占的场景下，内核执行代码被中断打断可能被其他进程抢占执行流。考虑下面的场景：
```
内核态 CPU0：

1. CPU0 执行进程 1 的系统调用内核路径，访问 CPU0 的每 CPU 变量 runqueue[0]。
2. 读取了进程描述符 A，准备将进程描述符 B 插入到 A 的所在链表后面，只执行到一半操作。
3. 时钟中断到来，CPU0 执行流被强行打断去执行时钟中断的中断服务例程。
4. 中断服务例程发现进程 2 的优先级更高，在退出中断服务例程之前，把 CPU0 切换到进程 2 的内核路径中。
5. 进程 2 的内核路径也读取了进程描述符 A，准备将进程描述符 C 插入到 A 的所在链表后面，并执行完成。
6. CPU0 调度进程 1 继续执行之前的内核路径，把剩余一半的操作继续完成。
```
可以看到，由于内核抢占机制，CPU0 runqueue[0] 数据被交替执行的逻辑破坏了。

在这个场景中，单纯的 pre-CPU 变量是一种互斥访问的*共识*吗？ 

*还不是*，虽然它看上去是，但是 kernel context 对中断的处理方式决定了，*pre-CPU 变量 + 禁止内核抢占* 才是一种对互斥访问的*共识*。 

我们通过这个例子更加深入体会了锁在不同 context 下是什么。

### 原子锁(原子变量)
看完无锁场景之后，让我们再往前推进一小步，假设业务的确需要使用多个并发流访问同一份数据，那我们能提供的最简约的互斥访问*共识* 是什么？

一个的想法是：*是否有可能对一小块内存块规定，在某种机制下，kernel context 能对它的互斥访问达成共识。*

比如：多线程多进程能对一个 4 字节的 int 变量达成共识，规定所有对 int 操作的 +1/-1 指令都是原子的，哪个线程优先把 int 变量设置成 1 就说明占有资源，否则不占有资源，在不占有资源的时候给上层返回错误，或者进程被移动到等待队列等。

这是个可行的假设，但是还要再具体一点，我们再假设所有的变量都只在主存中读写操作，没有任何缓存，并且处理器提供 CAS(Compare And Set) 原子指令。这样每个并发流都执行 cas(variable，old value, new value) 的时候，就能在整个 kernel context 中保证，不管并发流执行顺序是什么样子的，都能保证在任意时候有且仅有一个执行流能占有资源，这就是一种互斥访问的*共识*。

这就是我们的原子变量，或者我们叫原子锁。它的`读-修改-写`操作是原子的，不可分割的。这样并发执行流就能天然在这个内存块上串行操作了，因为它是最小的不可分割的操作单元。

并且更妙的是，基于这样一个锁原语，我们可以进行拓展，比如占有资源的并发流再去做其他更多事情，做完之后把资源释放掉(将 int 设置成 0)。

*我们到达终点了吗？*

**醒醒啊，我们才刚确认了正确的方向而已。**

真正的 kernel context 可不是我们上面假设的那样---所有的变量都只在主存中读写操作，硬件系统存在不同级别的缓存，比如有名的存储山结构，按访问延迟依次是寄存器、CPU 专有的 L1/L2 硬件缓存，CPU 共享的 L3 硬件缓存，再到共享的物理内存。

![memory-hierarchy](/assets//images/post/linux-kernel-synchronization/memory-hierarchy.png)

硬件系统层面对原子变量的操作语义支持是复杂的，我们可以想象的几个不一致的场景：
1. 变量内存不对齐 native word size，或者变量内存不在一次指令内存操作范围内，需要使用多个指令才能操作变量。多个 CPU 可能在指令之间交替执行，比如变量的前 8 字节和后 8 字节可能不在一个原子操作中。
2. 最简单的状态变更 a++ 需要的不是一个操作，而是 3 个操作，读取内存中 a 变量的值到寄存器，改寄存器，将寄存器的值回写内存。多个 CPU 可能在操作之间交替执行，比如导致更新丢失。
3. 在存储山结构中，部分存储是 CPU 专有的，比如寄存器 L1/L2，部分存储是 CPU 共享的，比如 L3/memory。对于共享存储，我们可以通过锁内存总线的方式串行化特定区域的内存访问，但是对于特有的存储，就可能存在有旧的变量值在硬件缓存 L1/L2 中，CPU 误认为自己获取了最新的值。

因此，对于原子变量的实现，在系统层面上需要以下几种机制保证：  
1.1 架构相关实现下，变量需要对齐 native word size 实现单个`读` 或`写`变量的原子操作，比如 8 bytes 变量需要地址低 3 bit 都为 0。  
1.2 架构相关实现下，保证操作可以翻译成单个指令执行。  
2. 对于`读-修改-写`操作，共享型内存提供锁内存总线的方式串行化不同 CPU 的访问，比如 lock 指令。
3. 对于`读-修改-写`操作，独享型内存提供处理器间机制，比如 MESI protocol，保证同一变量的不同缓存状态能互相影响，比如将其他 CPU 的高速缓存标记成失效状态。

通过以上机制，内核对外提供了非常简单直观的原子变量语义，比如：
```
struct atomic_int {
    int v;  // 一小块内存对齐的内存
};

define global struct atomic_int count;

int main() {
    atomic_inc(&count);
}
```

可能对应的汇编：
```
lock addl	$1, count(%rip)   // 锁总线+标记其他高速缓存失效
```

内核提供一些原子操作如下：
```
atomic_read(v)                // Return *v
atomic_add(i,v)               // Add i to *v
atomic_sub_and_test(i, v)     // Subtract i from *v and return 1 if the result is zero; 0 otherwise
```

原子变量提供了非常可靠的同步原语，所有的`读`/`写`/`读-修改-写`在多处理器上被认为是 instantly 和 simutaneously 的。这样对于同一个原子变量，多处理在该原子变量上的操作被同步了，最终表现出 some order，比如：

define atomic_int v;

| ts      |  P1     |   P2   |    P3  |
|---------|---------|--------|--------|
| t1      | read v  |        |        |
| t2      |         |        |write v |
| t3      |         |r-m-w v |        |
| t4      | write v |        |        |

好了，计算机大牛们终于帮我们迈过了锁历史上的一大步，我们得到了 kernel context 下对互斥访问的一个可靠*共识*。这种共识更多的是基于硬件系统的指令控制，比如内存总线锁和 MESI 缓存一致性协议，这些硬件指令细节都封装到了基于硬件系统的编译器中了。

### 锁的实现
基于原子变量这个可靠*共识*，我们可以开始看下在日常编程中使用的各种锁的真面目了，以及我们经常提及锁开销问题。

* critical segement/mutex
临界区或者锁，语义上是指锁占有失败能导致执行流(进程)阻塞挂起的锁。这类锁在实现上利用了 2 种机制：
1. 原子变量保证串行化并发流对资源的占有行为，有且只有一个执行流可以占有资源，并且占有资源的行为会立即被其他并发流看到。
2. 不占有资源的执行流被 kernel 挂起，放入锁等待队列中，等锁释放后再唤醒等待的并发执行流。

从实现机制上，我们可以看到这类阻塞锁的开销在于*原子变量在多级缓存中的同步协议开销*，*进程挂起唤醒*和*进程被唤醒等待调度延迟*。

*进程挂起唤醒* 这个在前面[进程调度 blog](https://maxshuang.github.io/linux-kernel/2024/01/11/Linux-Kernel-Process-Scheduler.html)中提到，内核除了会被异步硬件事件打断进入内核之外，还会被周期的时钟中断(通常 1ms) 打断在内核中进行优先级更新和进程调度，所以进程被挂起后唤醒是可能有 ms 级别的延迟的。

* spin lock
自旋锁，语义上是指锁占有失败能导致执行流轮询。这类锁在实现上利用了 2 种机制：
1. 原子变量保证串行化并发流对资源的占有行为，有且只有一个执行流可以占有资源，并且占有资源的行为会立即被其他并发流看到。
2. 不占有资源的执行流会空转一定的指令周期后，再次检查原子变量。

从实现机制上，可以看到 spin lock 具有*更快的调度速度*，可能是 ns 或者 us 级别的调度(和进程时间片轮转还有关)，不需要休眠等待唤醒，当然缺点也很明显，就是长时间的指令空转会浪费 CPU 指令周期。它的使用场景是，原子变量已经在各级缓存中，并且保护的代码区域非常短，并发冲突不强，内核中就经常使用。

* Semaphore
信号量，语义上允许在同一个时刻有多个执行流占用资源，而其他资源需要等待。这类锁在实现上利用了 2 种机制：
1. 原子变量 count=n 保证有且只有 n 个执行流可以占有资源，并且占有资源的行为会立即被其他并发流看到。
2. 不占有资源的执行流会被挂起。

信号量特别使用于生产者-消费者模式中，通过 Semaphore 控制读者的并发，从而保证读者的每次并发访问都能读取到有效的消息。

* Condition 
条件变量


* read-write lock
读写锁，提高读写并发的一类锁，读读不冲突，读写/写读/写写冲突。这类锁在实现上利用了几种机制：
1. 读者个数的原子变量，写者发现已经有读者需要排队等待，这个排队可以是忙等或者导致进程挂起。读者发现没有写者时，会递增该原子变量，读完后会递减该原子变量，已经有写者时可以采用不同的策略，要看设计上是读优先还是写优先，写优先的话读者就需要排队了。
2. 写者个数的原子变量，写对任何操作都是互斥的，所以只有在没有任何读者和写者时才可能获取到锁，否则只能排队等待调度。
3. 



